{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"![](https://theinnerdetail.com/wp-content/uploads/2021/07/aisong5.jpg)","metadata":{}},{"cell_type":"markdown","source":"# # Let's Get Started","metadata":{}},{"cell_type":"code","source":"#sudo apt-get update to install lilypond else might through error while installing the lilypond package\n!apt-get update\n!pip install music21\n!apt-get -y install lilypond","metadata":{"execution":{"iopub.status.busy":"2022-10-08T03:49:28.276104Z","iopub.execute_input":"2022-10-08T03:49:28.276546Z","iopub.status.idle":"2022-10-08T03:50:10.713919Z","shell.execute_reply.started":"2022-10-08T03:49:28.276462Z","shell.execute_reply":"2022-10-08T03:50:10.712769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <div style=\"padding:20px;color:white;margin:0;font-size:100%;text-align:left;display:fill;border-radius:5px;background-color:#6A79BA;overflow:hidden\">1 | Load The Libraries</div>","metadata":{}},{"cell_type":"code","source":"#Importing Libraries\nimport tensorflow \nimport numpy as np \nimport pandas as pd \nfrom collections import Counter\nimport random\nimport IPython\nfrom IPython.display import Image, Audio\nimport music21\nfrom music21 import *\nimport matplotlib.pyplot as plt \nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, Dense, Dropout\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.optimizers import Adamax\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as mpatches\n%matplotlib inline\nimport sys\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nwarnings.simplefilter(\"ignore\")\nnp.random.seed(42)","metadata":{"execution":{"iopub.status.busy":"2022-10-08T04:00:25.361889Z","iopub.execute_input":"2022-10-08T04:00:25.362274Z","iopub.status.idle":"2022-10-08T04:00:25.376772Z","shell.execute_reply.started":"2022-10-08T04:00:25.362243Z","shell.execute_reply":"2022-10-08T04:00:25.375813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <div style=\"padding:20px;color:white;margin:0;font-size:100%;text-align:left;display:fill;border-radius:5px;background-color:#6A79BA;overflow:hidden\">2 | LOADING DATA</div>","metadata":{}},{"cell_type":"code","source":"#Loading the list of  midi files as stream \nfilepath = \"../input/musicnet-midis/musicnet_midis/Brahms/\"\nimport os\n#Getting midi files\nall_midis= []\nfor i in os.listdir(filepath):\n    if i.endswith(\".mid\"):\n        tr = filepath+i\n        midi = converter.parse(tr)\n        all_midis.append(midi)\n        \n#this will take time to load\n\nprint(all_midis)","metadata":{"execution":{"iopub.status.busy":"2022-10-08T04:24:16.157187Z","iopub.execute_input":"2022-10-08T04:24:16.157555Z","iopub.status.idle":"2022-10-08T04:35:17.771133Z","shell.execute_reply.started":"2022-10-08T04:24:16.157526Z","shell.execute_reply":"2022-10-08T04:35:17.770128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(all_midis)","metadata":{"execution":{"iopub.status.busy":"2022-10-08T04:36:41.800495Z","iopub.execute_input":"2022-10-08T04:36:41.800858Z","iopub.status.idle":"2022-10-08T04:36:41.808483Z","shell.execute_reply.started":"2022-10-08T04:36:41.800827Z","shell.execute_reply":"2022-10-08T04:36:41.807534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now retrieve the components of the MIDI files, it can be either chords or notes.\n\nMIDI file format in brief:\nThe Standard MIDI File (SMF) is a file format that provides a standardized way for music sequences to be saved, transported, and opened in other systems.\n\nMID or. MIDI file extension is the Musical Instrument Digital (MID) Interface file. It is the difference from ordinary audio files such as WAVs or MP3s in that it doesn't carry the actual audio content; hence, is quite smaller in size.\n\nFor more details: https://docs.fileformat.com/audio/mid/\n\n\n**Note:** The musical notes are the building blocks of the music. It pertains to a pitch associated with a specific audio vibration. Western music utilizes twelve musical notes. \n\n**Chord:** A group of notes that sound good together is a chord.\n\nThe music21 stream that was created in the above cell contains both, chords and notes, we will extract them in the form of notes and obtain a series of notes in the musical composition.\n\n","metadata":{}},{"cell_type":"code","source":"#function defination to get the notes.\n    \ndef extract_notes(file):\n    notes = []\n    pick = None\n    for j in file:\n        songs = instrument.partitionByInstrument(j)\n        for part in songs.parts:\n            pick = part.recurse()\n            for element in pick:\n                if isinstance(element, note.Note):\n                    notes.append(str(element.pitch))\n                elif isinstance(element, chord.Chord):\n                    notes.append(\".\".join(str(n) for n in element.normalOrder))\n\n    return notes\n#Getting the list of notes as Corpus\nCorpus= extract_notes(all_midis)\nprint(\"Total notes in all the midi\", len(Corpus))\nprint(\"Notes of the MIDI file\",Corpus[:10])\nprint(\"Now as you see we have our music notes/chords in the corpus format.\")","metadata":{"execution":{"iopub.status.busy":"2022-10-08T04:36:44.415978Z","iopub.execute_input":"2022-10-08T04:36:44.416536Z","iopub.status.idle":"2022-10-08T04:37:02.900822Z","shell.execute_reply.started":"2022-10-08T04:36:44.416497Z","shell.execute_reply":"2022-10-08T04:37:02.89975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <div style=\"padding:20px;color:white;margin:0;font-size:100%;text-align:left;display:fill;border-radius:5px;background-color:#6A79BA;overflow:hidden\">3 | EDA: Exploratory Data Analysis</div>","metadata":{}},{"cell_type":"code","source":"#functions to print the MIDI notes\ndef show(music):\n    display(Image(str(music.write(\"lily.png\"))))\n    \ndef chords_n_notes(Snippet):\n    Melody = []\n    offset = 0 #Incremental\n    for i in Snippet:\n        #If it is chord\n        if (\".\" in i or i.isdigit()):\n            chord_notes = i.split(\".\") #Seperating the notes in chord\n            notes = [] \n            for j in chord_notes:\n                inst_note=int(j)\n                note_snip = note.Note(inst_note)            \n                notes.append(note_snip)\n                chord_snip = chord.Chord(notes)\n                chord_snip.offset = offset\n                Melody.append(chord_snip)\n        # pattern is a note\n        else: \n            note_snip = note.Note(i)\n            note_snip.offset = offset\n            Melody.append(note_snip)\n        # increase offset each iteration so that notes do not stack\n        offset += 1\n    Melody_midi = stream.Stream(Melody)   \n    return Melody_midi\n\nMelody_Snippet = chords_n_notes(Corpus[:100])\nshow(Melody_Snippet)","metadata":{"execution":{"iopub.status.busy":"2022-10-08T04:37:02.902893Z","iopub.execute_input":"2022-10-08T04:37:02.903521Z","iopub.status.idle":"2022-10-08T04:37:03.784938Z","shell.execute_reply.started":"2022-10-08T04:37:02.903484Z","shell.execute_reply":"2022-10-08T04:37:03.783749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Kaggle currently dont support MIDI files \n#Convert the MIDI files into wav format to play the sample audio\nprint(\"Sample Audio From Data\")\nIPython.display.Audio(\"../input/musicnet-midis/Output/haydn/2104_op64n5_1.mp3\") ","metadata":{"execution":{"iopub.status.busy":"2022-10-08T04:37:03.786812Z","iopub.execute_input":"2022-10-08T04:37:03.787138Z","iopub.status.idle":"2022-10-08T04:37:03.91951Z","shell.execute_reply.started":"2022-10-08T04:37:03.787106Z","shell.execute_reply":"2022-10-08T04:37:03.918141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Examine all the notes in the Corpus** ","metadata":{}},{"cell_type":"code","source":"#Creating a count dictionary\ncount_num = Counter(Corpus)\nprint(\"Total unique notes in the Corpus:\", len(count_num))\nprint(count_num)","metadata":{"execution":{"iopub.status.busy":"2022-10-08T04:37:19.942826Z","iopub.execute_input":"2022-10-08T04:37:19.94322Z","iopub.status.idle":"2022-10-08T04:37:19.964785Z","shell.execute_reply.started":"2022-10-08T04:37:19.943185Z","shell.execute_reply":"2022-10-08T04:37:19.963735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Exploring the notes dictionary\nNotes = list(count_num.keys())\nRecurrence = list(count_num.values())\n#Average recurrenc for a note in Corpus\ndef Average(lst):\n    return sum(lst) / len(lst)\nprint(\"Average recurrenc for a note in Corpus:\", Average(Recurrence))\nprint(\"Most frequent note in Corpus appeared:\", max(Recurrence), \"times\")\nprint(\"Least frequent note in Corpus appeared:\", min(Recurrence), \"time\")","metadata":{"execution":{"iopub.status.busy":"2022-10-08T04:37:23.96696Z","iopub.execute_input":"2022-10-08T04:37:23.967996Z","iopub.status.idle":"2022-10-08T04:37:23.975427Z","shell.execute_reply.started":"2022-10-08T04:37:23.967955Z","shell.execute_reply":"2022-10-08T04:37:23.97434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting the distribution of Notes to understand the rate notes or in other words anomalies\nplt.figure(figsize=(18,3),facecolor=\"#97BACB\")\nbins = np.arange(0,(max(Recurrence)), 50) \nplt.hist(Recurrence, bins=bins, color=\"#97BACB\")\nplt.axvline(x=100,color=\"#DBACC1\")\nplt.title(\"Frequency Distribution Of Notes In The Corpus\")\nplt.xlabel(\"Frequency Of Chords in Corpus\")\nplt.ylabel(\"Number Of Chords\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-10-08T04:37:27.389807Z","iopub.execute_input":"2022-10-08T04:37:27.390199Z","iopub.status.idle":"2022-10-08T04:37:27.793921Z","shell.execute_reply.started":"2022-10-08T04:37:27.390167Z","shell.execute_reply":"2022-10-08T04:37:27.792966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Getting a list of rare chords that are occured less than 100 times\nrare_note = []\nfor index, (key, value) in enumerate(count_num.items()):\n    if value < 100:\n        m =  key\n        rare_note.append(m)\n        \nprint(\"Total number of notes that occur less than 100 times:\", len(rare_note))","metadata":{"execution":{"iopub.status.busy":"2022-10-08T04:37:31.557799Z","iopub.execute_input":"2022-10-08T04:37:31.558197Z","iopub.status.idle":"2022-10-08T04:37:31.566137Z","shell.execute_reply.started":"2022-10-08T04:37:31.558162Z","shell.execute_reply":"2022-10-08T04:37:31.563928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Eleminating the rare notes\nfor element in Corpus:\n    if element in rare_note:\n        Corpus.remove(element)\n\nprint(\"Length of Corpus after elemination the rare notes:\", len(Corpus))","metadata":{"execution":{"iopub.status.busy":"2022-10-08T04:37:32.615341Z","iopub.execute_input":"2022-10-08T04:37:32.615705Z","iopub.status.idle":"2022-10-08T04:37:36.144239Z","shell.execute_reply.started":"2022-10-08T04:37:32.615673Z","shell.execute_reply":"2022-10-08T04:37:36.143073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <div style=\"padding:20px;color:white;margin:0;font-size:100%;text-align:left;display:fill;border-radius:5px;background-color:#6A79BA;overflow:hidden\">4 | DATA PREPROCESSING</div>\n","metadata":{}},{"cell_type":"code","source":"# Storing all the unique characters present in my corpus to bult a mapping dic. \nsymb = sorted(list(set(Corpus)))\n\nL_corpus = len(Corpus) #length of corpus\nL_symb = len(symb) #length of total unique characters\n\n#Building dictionary to map the notes and their indices and vice versa to retreive the values during predict\nmapping = dict((c, i) for i, c in enumerate(symb))\nreverse_mapping = dict((i, c) for i, c in enumerate(symb))\n\nprint(\"Total number of characters:\", L_corpus)\nprint(\"Number of unique characters:\", L_symb)\n\nprint(\"Mapping Values\",mapping)\nprint(\"Reverse Mapping Values\", reverse_mapping)\n","metadata":{"execution":{"iopub.status.busy":"2022-10-08T04:37:40.659477Z","iopub.execute_input":"2022-10-08T04:37:40.659891Z","iopub.status.idle":"2022-10-08T04:37:40.671289Z","shell.execute_reply.started":"2022-10-08T04:37:40.659855Z","shell.execute_reply":"2022-10-08T04:37:40.670089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Splitting the Corpus in equal length of strings and output target\nlength = 40\nfeatures = []\ntargets = []\nfor i in range(0, L_corpus - length, 1):\n    feature = Corpus[i:i + length]\n    target = Corpus[i + length]\n    features.append([mapping[j] for j in feature])\n    targets.append(mapping[target])\n    \n    \nL_datapoints = len(targets)\nprint(\"Total number of sequences in the Corpus:\", L_datapoints)\nprint(\"Target values preview~\", targets[:10])\nprint(\"Feature values preview~\", features[1])","metadata":{"execution":{"iopub.status.busy":"2022-10-08T04:37:50.285629Z","iopub.execute_input":"2022-10-08T04:37:50.286599Z","iopub.status.idle":"2022-10-08T04:37:50.853546Z","shell.execute_reply.started":"2022-10-08T04:37:50.286549Z","shell.execute_reply":"2022-10-08T04:37:50.852447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# reshape X and normalize\nX = (np.reshape(features, (L_datapoints, length, 1)))/ float(L_symb)\n# one hot encode the output variable\ny = tensorflow.keras.utils.to_categorical(targets) \n\nprint(\"Shape of the X is{} and Y is{} \".format(X.shape,y.shape))\n","metadata":{"execution":{"iopub.status.busy":"2022-10-08T04:37:54.405125Z","iopub.execute_input":"2022-10-08T04:37:54.405802Z","iopub.status.idle":"2022-10-08T04:37:54.804347Z","shell.execute_reply.started":"2022-10-08T04:37:54.405765Z","shell.execute_reply":"2022-10-08T04:37:54.803138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Taking out a subset of data to be used as seed\nX_train, X_seed, y_train, y_seed = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-10-08T04:37:59.235659Z","iopub.execute_input":"2022-10-08T04:37:59.236547Z","iopub.status.idle":"2022-10-08T04:37:59.314715Z","shell.execute_reply.started":"2022-10-08T04:37:59.23651Z","shell.execute_reply":"2022-10-08T04:37:59.313543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <div style=\"padding:20px;color:white;margin:0;font-size:100%;text-align:left;display:fill;border-radius:5px;background-color:#6A79BA;overflow:hidden\">5 | MODEL BUILDING</div>\n","metadata":{}},{"cell_type":"code","source":"#Initialising the Model\nmodel = Sequential()\n#Adding layers\nmodel.add(LSTM(512, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\nmodel.add(Dropout(0.1))\nmodel.add(LSTM(256))\nmodel.add(Dense(256))\nmodel.add(Dropout(0.1))\nmodel.add(Dense(y.shape[1], activation='softmax'))\n#Compiling the model for training  \nopt = Adamax(learning_rate=0.01)\nmodel.compile(loss='categorical_crossentropy', optimizer=opt)\n","metadata":{"execution":{"iopub.status.busy":"2022-10-08T04:38:01.358379Z","iopub.execute_input":"2022-10-08T04:38:01.358752Z","iopub.status.idle":"2022-10-08T04:38:02.086603Z","shell.execute_reply.started":"2022-10-08T04:38:01.358717Z","shell.execute_reply":"2022-10-08T04:38:02.085494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Model's Summary               \nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-10-08T04:38:06.129841Z","iopub.execute_input":"2022-10-08T04:38:06.130236Z","iopub.status.idle":"2022-10-08T04:38:06.13681Z","shell.execute_reply.started":"2022-10-08T04:38:06.130201Z","shell.execute_reply":"2022-10-08T04:38:06.135864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Training the Model\nhistory = model.fit(X_train, y_train, batch_size=256, epochs=200)","metadata":{"execution":{"iopub.status.busy":"2022-10-08T04:38:09.350389Z","iopub.execute_input":"2022-10-08T04:38:09.350766Z","iopub.status.idle":"2022-10-08T05:13:14.763934Z","shell.execute_reply.started":"2022-10-08T04:38:09.350731Z","shell.execute_reply":"2022-10-08T05:13:14.763013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n# <div style=\"padding:20px;color:white;margin:0;font-size:100%;text-align:left;display:fill;border-radius:5px;background-color:#6A79BA;overflow:hidden\">6 | Model Evaluation </div>","metadata":{}},{"cell_type":"code","source":"#Plotting the learnings against loss\nhistory_df = pd.DataFrame(history.history)\nfig = plt.figure(figsize=(15,4), facecolor=\"#97BACB\")\nfig.suptitle(\"Learning Plot of Model for Loss\")\npl=sns.lineplot(data=history_df[\"loss\"],color=\"#444160\")\npl.set(ylabel =\"Training Loss\")\npl.set(xlabel =\"Epochs\")","metadata":{"execution":{"iopub.status.busy":"2022-10-08T05:13:24.323233Z","iopub.execute_input":"2022-10-08T05:13:24.323604Z","iopub.status.idle":"2022-10-08T05:13:24.68096Z","shell.execute_reply.started":"2022-10-08T05:13:24.323572Z","shell.execute_reply":"2022-10-08T05:13:24.679981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#function defination to generate/predict new lyrics/music in the mid format\n\ndef Malody_Generator(Note_Count):\n    seed = X_seed[np.random.randint(0,len(X_seed)-1)]\n    Music = \"\"\n    Notes_Generated=[]\n    for i in range(Note_Count):\n        seed = seed.reshape(1,length,1)\n        prediction = model.predict(seed, verbose=0)[0]\n        prediction = np.log(prediction) / 1.0 #diversity\n        exp_preds = np.exp(prediction)\n        prediction = exp_preds / np.sum(exp_preds)\n        index = np.argmax(prediction)\n        index_N = index/ float(L_symb)   \n        Notes_Generated.append(index)\n        Music = [reverse_mapping[char] for char in Notes_Generated]\n        seed = np.insert(seed[0],len(seed[0]),index_N)\n        seed = seed[1:]\n    #Now, we have music in form or a list of chords and notes and we want to be a midi file.\n    #print(Music)\n    Melody = chords_n_notes(Music)\n    Melody_midi = stream.Stream(Melody)   \n    return Music,Melody_midi\n\n\n#getting the Notes and Melody created by the model\nMusic_notes, Melody = Malody_Generator(100)\nshow(Melody)\nprint(\"Music Notes of the above \",Music_notes)\n","metadata":{"execution":{"iopub.status.busy":"2022-10-08T05:13:28.184897Z","iopub.execute_input":"2022-10-08T05:13:28.185593Z","iopub.status.idle":"2022-10-08T05:13:33.304008Z","shell.execute_reply.started":"2022-10-08T05:13:28.185556Z","shell.execute_reply":"2022-10-08T05:13:33.302607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Time to generate the new music ~","metadata":{}},{"cell_type":"code","source":"#To save the generated melody\nMelody.write('midi','newly_generated_music_notes.mid')\n#check the output folder for the file\n","metadata":{"execution":{"iopub.status.busy":"2022-10-08T05:13:49.360689Z","iopub.execute_input":"2022-10-08T05:13:49.361128Z","iopub.status.idle":"2022-10-08T05:13:49.411345Z","shell.execute_reply.started":"2022-10-08T05:13:49.36108Z","shell.execute_reply":"2022-10-08T05:13:49.410436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Convert the mid format file to wav, .mp3 \n#using https://audio.online-convert.com/convert/mid-to-mp3\n#to play audio or corpus\nIPython.display.Audio(\"../input/musicnet-midis/Output/newly_generated_music_notes.mp3\")","metadata":{"execution":{"iopub.status.busy":"2022-10-08T05:21:08.347365Z","iopub.execute_input":"2022-10-08T05:21:08.347753Z","iopub.status.idle":"2022-10-08T05:21:08.39055Z","shell.execute_reply.started":"2022-10-08T05:21:08.347719Z","shell.execute_reply":"2022-10-08T05:21:08.388137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <div style=\"padding:20px;color:white;margin:0;font-size:100%;text-align:left;display:fill;border-radius:5px;background-color:#6A79BA;overflow:hidden\">7 | Conclusion</div>\n\nThe main take away is the music21 package that helps us to convert the mid format music files to our regular numerical values and then reframe it into LSTM input shape.\n\nThus we can use other sequential algorithms like chain classifiers to train and predict sequential data points.\n\nWill be updating the notebook with other algorithms to experiment outputs in N scenarios, meanwhile you can  go ahead to the link https://www.youtube.com/watch?v=Emidxpkyk6o to listen one of the Ai created music. \n\n**This is a open source project any collab for further development is most welcome.**\n\n***MeanWhile Enjoy....!**\n\n![](https://i.ytimg.com/vi/Emidxpkyk6o/maxresdefault.jpg)\n\n","metadata":{}}]}